---
title: "Delfina take-home assessment"
author: "Leonardo Hernandez Espinoza"
date: "2022-07-30"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(data.table)
library(formattable)
library(ROCR)
library(pROC)
library(randomForest)

set.seed(2007)
```

## Import the data

```{r}
# If you are testing this outside my repo, please change the url
data_url <- "~/R/delfina-ds-interview/data/birthdata2020.csv"
birth_data <- read.csv(data_url, header = TRUE)
```

## Task 1:  What is the proportion of births by gestational age at delivery
I am answering this question as the proportion of births at each one of the combined gestation weeks based on the column COMBGEST.

Given that COMBGEST uses the value 99 as a filler value to denote missing data I will remove that value. 
I am also filtering the data to limit the results to values between 20 and 50 weeks, that range was selected based on information found [here](https://www.health.ny.gov/community/pregnancy/why_is_40_weeks_so_important.htm#:~:text=How%20long%20is%20full%20term%3F).

```{r}
birth_data %>% 
  filter(COMBGEST %in% (20:50)) %>% 
  ggplot(aes(COMBGEST))+
  geom_bar(aes(y = (..count..)/sum(..count..)), fill = 'blue') +
  theme_classic()+
  xlab("Number of weeks at birth")+
  ylab("Proportion of births")
```
<br>
As we can see, the largest proportion of births occur between 39 and 41 weeks of gestation.


## Task 2:  What is the prevalence of preterm birth in this dataset?
To answer this question I will create a flag variable (is_preterm) to indicate if the birth occurred prior to 37 weeks of gestation (based on COMBGEST). In order to better calculate the proportion of preterm birth that occurred during 2020, I will exclude those cases where <br>COMBGEST =99.

From this point on, the is_preterm column will be used multiple times so I will fist add it to the data set.
```{r}
birth_data <- birth_data %>% 
  filter(COMBGEST != 99) %>% 
  mutate(is_preterm = case_when(
    COMBGEST < 37 ~ "Yes",
    TRUE ~ "No"
  ))


```
With the new column added, I then evaluate the proportions of preterm births
```{r}
 task2_table <- birth_data %>% 
  group_by(is_preterm) %>% 
  summarise(n_cases = n()) %>%
  mutate(percentage = 100* round(n_cases / sum(n_cases), 4)) %>% 
  data.table()
```
I will use the `formattable` package for better aesthetics 
```{r}
formattable(task2_table)
```

We can see that from all the observations in the data set, less ~12% of the cases are preterm births.

## Task 3: Summarizes the relationship between preterm birth and the following four variables:

  - Maternal age (MAGER)

  - Maternal race/Hispanic origin (MRACEHISP)

  - Previous preterm birth (RF_PPTERM)

  - Total number of prenatal visits (PREVIS)


Based on the example given, I will compare the number of births (preterm and not) across the four variables listed above.

I will create dummy categorical variables to create bins for Maternal age (MAGER) and for the total number or prenatal visits (PREVIS). By creating bins I will aggregate those variables into fewer categorical values that would contain more observations and therefore will help focus the message in the data. 

***Note:*** in each of the following tables the `No` and `Yes` columns represent whether a birth was preterm or not.

First I will create the bins for Maternal Age:
```{r }
MAGER_cuts <- c(0,19,29,39,49,59)
MAGER_labs <- c("19 and under", "20-29", "30-39", "40-49",  "50 and over")

birth_data <- birth_data %>% 
  mutate(age_bins = cut(MAGER, breaks=MAGER_cuts, labels=MAGER_labs ))
```


To create the bins for the total number or prenatal visits (PREVIS) I will first replace the value 99 that was used as a code signifying an unknown number of visits with NA. This way those observations will not be binned.

To define the bins I created a series of histograms to visualize the distribution of the observations and inform my decision (for more details see the sandbox file)

```{r}
PREVIS_cuts <- c(0,5,10,15,100)
PREVIS_labels <- c("Less than 5", "5-9",
                   "10-14", "15 and over")

birth_data <- birth_data %>% 
  mutate(PREVIS = na_if(PREVIS, 99)) %>% 
  mutate(PREVIS_bins = cut(PREVIS, breaks =PREVIS_cuts, right=FALSE, labels=PREVIS_labels))
```

After creating the new features I can now summarize the number of births (preterm or not) for each category of the following variables:

### age_bins


```{r}
ct_age_bins <- birth_data %>% 
  group_by(is_preterm, age_bins) %>% 
  tally() %>% 
  spread(is_preterm, n)

formattable(ct_age_bins, align = c("l", rep("r", NCOL(ct_age_bins) - 1)))
```

### MRACEHISP

MRACEHISP is a numerical code that represents the mother's race and whether she is Hispanic  or not. The numerical code makes it difficult to understand the data. Therefore I will create a new and more intuitive column (`MRACE_strg`).

```{r}
birth_data <- birth_data %>%
  mutate(MRACE_strg = recode(MRACEHISP,
                             `1` = "White",
                             `2` = "Black",
                             `3` = "AIAN",
                             `4` = "Asian",
                             `5` = "NHOPI",
                             `6` = "Mixed",
                             `7` = "Hispanic",
                             `8` = "Unknown"))
```


```{r}
ct_MRACEHISP<- birth_data %>% 
  group_by(is_preterm, MRACE_strg) %>% 
  tally() %>% 
  spread(is_preterm, n)

formattable(ct_MRACEHISP, align = c("l", rep("r", NCOL(ct_MRACEHISP) - 1)))
```

### RF_PPTERM
Whether the previous birth was a preterm one is coded as Y, N, U. There are only 4 cases where the information was unknown so I will filter those out. The remaining ones I will recode for clarity.
```{r}
ct_RF_PPTERM <- birth_data %>% 
  filter(RF_PPTERM != "U") %>% 
  mutate(RF_PPTERM = recode(RF_PPTERM,
                            `Y` = "Yes",
                            `N`= "No",
                            )) %>% 
  group_by(is_preterm, RF_PPTERM) %>% 
  tally() %>% 
  spread(is_preterm, n)

formattable(ct_RF_PPTERM, align = c("l", rep("r", NCOL(ct_RF_PPTERM) - 1)))
```



### PREVIS_bins
```{r}
ct_PREVIS_bins <- birth_data %>% 
  group_by(is_preterm, PREVIS_bins) %>% 
  tally() %>% 
  spread(is_preterm, n) %>% 
  data.table()

formattable(ct_PREVIS_bins, align = c("l", rep("r", NCOL(ct_PREVIS_bins) - 1)))
```

I wanted to combine all this tables into a single one (as the one on the example paper), but couldn't get to work. I think the DT package can be used here, but I would need to look into it. However, this may be one of those cases where a spreadsheet would be a better(and faster) solution.

## Task 4: Predicting preterm bith in response to  Maternal age, Maternal race, whether the previous bith was preterm, and the total number of prenatal visits.



### Data Prepaparion
From this point forward I will be only using is_preterm, MAGER, MRACEHISP, RF_PPTERM, PREVIS so I will create a new data frame with only those columns and remove the raw data to clear up space in the session. I will cast `is_preterm` as a factor.

```{r}
birth_data_narrow <- birth_data %>% 
  select(is_preterm, MAGER,
         MRACEHISP, RF_PPTERM, PREVIS) %>% 
  na.omit() %>% 
  mutate(RF_PPTERM = recode(RF_PPTERM,
                            `Y` = 1,
                            `N`= 0,
                             `U` = 999
                            ),
         is_preterm = as.factor(is_preterm),
         RF_PPTERM = as.factor(RF_PPTERM)
         ) 

```



I will split the data into a training set (80%) and testing set (20%), in order to evaluate performance

```{r}
splitter_idx <- sample(nrow(birth_data_narrow),nrow(birth_data_narrow)*0.80)
birth_train_data = birth_data_narrow[splitter_idx,]
birth_test_data = birth_data_narrow[-splitter_idx,]
```



### Logistic Regression model
```{r}
logistic_model_train <- glm(is_preterm~MAGER+MRACEHISP+RF_PPTERM+PREVIS, data= birth_train_data,family="binomial")
summary(logistic_model_train)
```
Based on the summary data we can see that MAGER and MRACEHISP are not statistically significant. This makes them good candidates to be removed from the model and see if there is an improvement on AIC.

### ROC curve
First we need to obtain the probability outcome of each observation
```{r}
pred_logistic_model <- predict(logistic_model_train, type="response", newdata =birth_test_data[,-1] )
```


```{r}
prediction_and_labels_df <- data.frame(pred_logistic_model, birth_test_data$is_preterm)
names(prediction_and_labels_df) <- c("predictions", "labels")

#remove nas
prediction_and_labels_clean <- na.omit(prediction_and_labels_df)

```




```{r}
pred <- prediction(prediction_and_labels_clean$predictions, prediction_and_labels_clean$labels)
perf <- performance(pred, "tpr", "fpr")
plot(perf)
abline(coef = c(0,1))
```

### AUROC value

```{r}
auc <- performance(pred, measure = "auc")
auc <- auc@y.values[[1]]
print(paste0("The AUC values is: ", round(auc,3)))
```

## Task 5: ML approach to predict preterm births

I will use a random forest classifier as it is a good place to start.

```{r}
rf_model <- randomForest(is_preterm ~ ., data=birth_train_data, proximity=TRUE, na.action=na.roughfix)
rf_model
```

### ROC

```{r}
rf_prediction_roc <-  predict(rf_model, type="prob", newdata =birth_test_data[,-1] )[,2]

pred_rf = prediction(rf_prediction_roc, birth_test_data[,1]) 
perf <- performance(pred_rf, "tpr", "fpr")
plot(perf)
abline(coef = c(0,1))
```

### AUROC value
```{r}
auc_rf <- performance(pred_rf, measure = "auc")
auc_rf <- auc_rf@y.values[[1]]
print(paste0("The AUC values is: ", round(auc_rf,3)))

```

## Task 6: 


When using ML approaches we have to consider whether the increased complexity is needed and justified. A random forest model is a good starting place because it is easy to train, and more importantly easy to understand.

For this case in particular I decided on random forest because it can use both discrete and continuous variables. In addition, random forest models are less prone to over fitting because they use ensemble learning. 

To perform the analysis I started by splitting the data into a training and testing set. I used the training set to train the model using the `randomForest` function.  After the model was trained I generated predictions based on the testing set (without including the dependent variable). Those predictions were then used to generate the ROC curve and the AUC values using the `ROCR` package.



## Task 7: Comparing the models

In this case based on AUC values we can see that the logistic model is performing better than the random forest classifier. However, it is important to keep in mind that these model include variables that may not be contributing to the predictive power of both models, and additional models should be trained while reducing the number or independent variables.